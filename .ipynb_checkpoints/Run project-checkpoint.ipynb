{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import network_components\n",
    "import network_optimizers\n",
    "from senti_net import network\n",
    "import cPickle\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython import display\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.795156956\n"
     ]
    }
   ],
   "source": [
    "# Load in the data\n",
    "\n",
    "start = time.time()\n",
    "with open('./data/ready_data_840B_300d.pkl', 'r') as f:\n",
    "    data_dict = cPickle.load(f)\n",
    "    \n",
    "dur = time.time() - start\n",
    "print dur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequently used plotting functions\n",
    "\n",
    "def smooth_rep(data,sigma):\n",
    "    w = np.ceil(2*sigma)\n",
    "    f = np.exp( -.5*(np.arange(-w,w)**2)/(sigma**2) )\n",
    "    f = f / np.sum(f)\n",
    "    \n",
    "    for rnds in range(3):\n",
    "        for i in range(len(data)-1):\n",
    "            if np.isinf(data[i]) or np.isnan(data[i]):\n",
    "                data[i]=data[i+1]\n",
    "\n",
    "    y = np.convolve(data,f,'valid')\n",
    "    x = np.arange(w,len(data)-w+1)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def box_rep(data, sz):\n",
    "    x = np.arange(float(len(data)))\n",
    "    x_cs = np.cumsum(x)\n",
    "    y_cs = np.cumsum(data)\n",
    "    return (x_cs[sz:] - x_cs[:-sz]) / sz, (y_cs[sz:] - y_cs[:-sz]) / sz\n",
    "\n",
    "\n",
    "def plot_cost(ax, cost_history, start=0, smooth_sigma=50, max_y = 250., skip=1):\n",
    "    l = len(cost_history)\n",
    "    assert l >= start\n",
    "    c = cost_history[start:]\n",
    "    \n",
    "    c = c[::skip]\n",
    "    l = len(c)\n",
    "    \n",
    "    smooth_sigma = np.minimum(smooth_sigma, np.ceil(len(c)/2.))\n",
    "    \n",
    "    # Plot the dooder with all the points\n",
    "    ax[0].cla()\n",
    "    ax[0].plot(start+(np.arange(l)*skip), c, '.');\n",
    "    if l > smooth_sigma:\n",
    "        smth_x, smth_y = box_rep(c, smooth_sigma/skip)\n",
    "        smth_x = start + (smth_x*skip)\n",
    "        ax[0].plot(smth_x, smth_y, 'r', linewidth=3)\n",
    "        \n",
    "        smooth_sigma = int(smooth_sigma)\n",
    "        \n",
    "        max_dat = np.max(c)\n",
    "        y_cand = np.minimum(max_y, max_dat)\n",
    "        ax[0].set_ylim([np.maximum(-500,np.min(c)-.2),\n",
    "                        np.minimum(3000,np.maximum(y_cand, .2+np.max(c[-smooth_sigma:])))])\n",
    "    else:\n",
    "        ax[0].set_ylim([np.maximum(-500,np.min(c)-.2),\n",
    "                        np.minimum(3000,np.minimum(2000, np.max(c)+.2))])\n",
    "    \n",
    "    ax[0].grid(axis='y')\n",
    "    ax[0].set_xlim([start, start+(skip*l)])\n",
    "    \n",
    "    # Provide a visualization of just the smoothed one\n",
    "    if l > smooth_sigma:\n",
    "        ax[1].cla()\n",
    "        ax[1].plot(smth_x, smth_y, 'r', linewidth=3)\n",
    "        xs = [start, start+(skip*l)]\n",
    "        ax[1].plot(xs,[smth_y[-1], smth_y[-1]], 'k')\n",
    "        ax[1].set_xlim(xs)\n",
    "        ax[1].grid(axis='y')\n",
    "    \n",
    "    \n",
    "def plot_pcs(ax_pair_list_or_fig, pc_pairs, labels, ys, n_back=100, cmap='nipy_spectral', bg=.5):\n",
    "    # pc_pairs must be a list of pairs (where each pair is expressed as a list)\n",
    "    assert type(pc_pairs) == list\n",
    "    for pair in pc_pairs:\n",
    "        assert len(pair)==2\n",
    "    n_pairs = len(pc_pairs)\n",
    "    \n",
    "    if type(ax_pair_list_or_fig) == list:\n",
    "        # Assume a list of axes, set up in the same way as pc_pairs\n",
    "        for pair in ax_pair_list_or_fig:\n",
    "            assert len(pair)==2\n",
    "        assert len(ax_pair_list_or_fig)==n_pairs\n",
    "        ax_list = ax_pair_list_or_fig\n",
    "    else:\n",
    "        # Assume an empty figure object. Fill it with sub axes to match pc_pairs\n",
    "        fig = ax_pair_list_or_fig\n",
    "        ax_list = []\n",
    "        for i in range(n_pairs):\n",
    "            ax_list += [[fig.add_subplot(n_pairs, 2, j+1+(2*i)) for j in range(2)]]\n",
    "    \n",
    "    if ys.shape[2] > 1:\n",
    "        # Get your PCs and their projections\n",
    "        l = labels[:, -n_back:].flatten()\n",
    "        y = ys[:, :, -n_back:]\n",
    "        y = np.vstack([y[:,i,:].flatten() for i in range(y.shape[1])])\n",
    "        eD, eV = np.linalg.eig(np.cov(y))\n",
    "        eV = eV * np.sign(eV[0,])\n",
    "        proj = np.dot(eV.T, y)\n",
    "\n",
    "        # Step through each axis/pc pair and plot them\n",
    "        cmap = plt.get_cmap(cmap)\n",
    "        for ax_pc_pair in zip(ax_list, pc_pairs):\n",
    "            # Unpack\n",
    "            axs = ax_pc_pair[0]\n",
    "            pcs = ax_pc_pair[1]\n",
    "            for ax in axs: ax.cla()\n",
    "            # Alternately plot the points for each digit\n",
    "            for i, cidx in enumerate(np.linspace(0, 256, 10)):\n",
    "                idx = l==i\n",
    "                axs[(i%2)].plot(proj[pcs[0],idx], proj[pcs[1],idx], '.', c=cmap(int(cidx)), markersize=10);\n",
    "            # Apply the desired background color\n",
    "            for ax in axs:\n",
    "                ax.set_axis_bgcolor(bg*np.ones(3))\n",
    "            axs[0].set_ylabel(\"{} vs {}\".format(pcs[0], pcs[1]))\n",
    "\n",
    "\n",
    "def open_scatter(ax, indices, s=160, c='k', w=3):\n",
    "    return ax.scatter(indices%20, np.floor(indices/20), s=s, edgecolor=c, linewidths=w, facecolor='none')\n",
    "\n",
    "def plot_acc(ax, acc, eval_interval, start_at=0, xlim=None):\n",
    "    \"\"\"\n",
    "    Plot accuracy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axis handle\n",
    "    acc: a list of accuracies, sampled at a consistent interval\n",
    "    eval_interval: integer, the accuracy sampling interval\n",
    "    start_at: the earliest time (in training iterations) to display\n",
    "    xlim: x-axis limit of the plot\n",
    "    \"\"\"\n",
    "    # Figure out the best index to start from\n",
    "    i_start = int(np.ceil(start_at/float(eval_interval)))\n",
    "    \n",
    "    # Trim the data to this interval\n",
    "    acc_plot = acc[i_start:]\n",
    "    # Make the appropriate x-data for this\n",
    "    xdata = (np.arange(i_start, len(acc))+1)*eval_interval\n",
    "    \n",
    "    ax.cla()\n",
    "    ax.plot(xdata, acc_plot, 'o')\n",
    "    \n",
    "    if xlim is None:\n",
    "        xlim = [xdata[0]-eval_interval, xdata[-1]+eval_interval]\n",
    "    \n",
    "    if len(acc_plot) >= 2:\n",
    "        # Apply vanilla linear regression to visualize the trend\n",
    "        xt = xdata-np.mean(xdata)\n",
    "        y  = np.array(acc_plot)\n",
    "        yt = y-np.mean(y)\n",
    "        r = (yt.dot(xt)) / (xt.dot(xt))\n",
    "        o = np.mean(y)\n",
    "\n",
    "        rx = (np.array(xlim)-np.mean(xdata))*r + o\n",
    "        ax.plot(xlim, rx, 'k-')\n",
    "    \n",
    "    ax.grid(axis='y')\n",
    "    ax.set_xlim(xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_do(network, no_improve_limit, plot_every=10, plot_window=None, smooth_sigma=250):\n",
    "    if plot_window is None:\n",
    "        plot_window = no_improve_limit\n",
    "    \n",
    "    # Ready the figure\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax1_2 = [fig.add_subplot(3,1,1), fig.add_subplot(3,1,2)];\n",
    "    ax3 = fig.add_subplot(3,1,3);\n",
    "    \n",
    "    # Apply a number of training rounds\n",
    "    while network.no_improve_count <= no_improve_limit:\n",
    "\n",
    "        # Pull data\n",
    "        i_seq, s_len, t, _ = network.pull_data(data_dict['train'])\n",
    "\n",
    "        network.adam_helpers(i_seq, s_len, t)\n",
    "        this_cost = network.adam_train(i_seq, s_len, t)\n",
    "\n",
    "        # Log\n",
    "        network.cost_each_step += [this_cost]\n",
    "\n",
    "        # Check dev accuracy\n",
    "        if (len(network.cost_each_step) % network.eval_dev_every) == 0:\n",
    "            this_acc = network.check_accuracy(data_dict['dev'])\n",
    "            network.dev_acc += [this_acc]\n",
    "            if this_acc > network.best_dev_acc:\n",
    "                network.no_improve_count = 0\n",
    "                network.best_dev_acc = this_acc\n",
    "                network.best_dev_idx = len(network.cost_each_step)\n",
    "                network.best_dev_tup = network.snapshot()\n",
    "            else:\n",
    "                network.no_improve_count += 1\n",
    "\n",
    "        # Plot\n",
    "        start_at = np.maximum(0, len(network.cost_each_step)-plot_window)\n",
    "        if (len(network.cost_each_step) % plot_every) == 0:\n",
    "            plot_cost(ax1_2, network.cost_each_step, start=start_at, skip=1, smooth_sigma=250, max_y=1.3)\n",
    "\n",
    "            plot_acc(ax3, network.dev_acc, network.eval_dev_every, start_at, xlim=ax1_2[0].get_xlim())\n",
    "            ylim = ax3.get_ylim()\n",
    "            ax3.plot([network.best_dev_idx, network.best_dev_idx], ylim, 'r-')\n",
    "            ax3.set_ylim(ylim)\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(fig)\n",
    "\n",
    "    network.end_of_train_tup = network.snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_eval(network, baseline_mean, baseline_std):\n",
    "    # Check performance at the point in training with the best dev performance\n",
    "    network.restore(network.best_dev_tup)\n",
    "    print 'At best Dev performance...'\n",
    "    print '\\nTrain accuracy (appoximate): '\n",
    "    network.check_accuracy(data_dict['train'], 2000);\n",
    "    print '\\nDev accuracy: '\n",
    "    network.check_accuracy(data_dict['dev']);\n",
    "    print '\\nTest accuracy: '\n",
    "    network.check_accuracy(data_dict['test']);\n",
    "    \n",
    "    # Check the performance at the termination of training\n",
    "    network.restore(network.end_of_train_tup)\n",
    "    print '\\n\\nAt end of training...'\n",
    "    print '\\nTrain accuracy (appoximate): '\n",
    "    network.check_accuracy(data_dict['train'], 2000);\n",
    "    print '\\nDev accuracy: '\n",
    "    network.check_accuracy(data_dict['dev']);\n",
    "    print '\\nTest accuracy: '\n",
    "    a = 100.*network.check_accuracy(data_dict['test']);\n",
    "\n",
    "    # Compare to the goal\n",
    "    print '\\n\\nProbability this score beats Sheng Tai baseline:'\n",
    "    print '{}%'.format(\n",
    "        100.*np.round(1000.*np.mean(np.random.normal(baseline_mean, baseline_std, 10000) < a))/1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-layer vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6389200687\n"
     ]
    }
   ],
   "source": [
    "# Build a 1-layer vanilla LSTM\n",
    "inp_dim = 300\n",
    "inp_dropout = 0.5\n",
    "layer_specs = [(168, 0.5)]\n",
    "\n",
    "# Build the LSTM \"stack\"\n",
    "S = network_components.LSTM_stack(inp_dim, layer_specs, inp_dropout, init_fun=network_components.ortho_weight)\n",
    "S.initialize_stack_weights(b_f_offset=1.0)\n",
    "# Add the output sigmoid layer\n",
    "O = network_components.single_class_sigmoid(S.out_dim)\n",
    "\n",
    "# Create the network\n",
    "net_LSTM_1_binary = network(S, O, bi_flag=False, fine_grained=False, batch_size=25, eval_dev_every=50, alpha=0.005)\n",
    "\n",
    "\n",
    "# Train it\n",
    "train_do(net_LSTM_1_binary, no_improve_limit=56, plot_window=3000)\n",
    "\n",
    "\n",
    "# See how you did\n",
    "full_eval(net_LSTM_1_binary, baseline_mean=84.9, baseline_std=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-layer Bi-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.44789505\n"
     ]
    }
   ],
   "source": [
    "# Build a 1-layer bi-directional LSTM\n",
    "inp_dim = 300\n",
    "inp_dropout = 0.5\n",
    "layer_specs = [(168, 0.5)]\n",
    "\n",
    "# Build the LSTM \"stack\"\n",
    "S = network_components.BiLSTM_stack(inp_dim, layer_specs, inp_dropout, init_fun=network_components.ortho_weight)\n",
    "S.initialize_stack_weights(b_f_offset=1.0)\n",
    "# Add the output sigmoid layer\n",
    "O = network_components.single_class_sigmoid(S.out_dim)\n",
    "\n",
    "# Create the network\n",
    "net_LSTM_1B_binary = network(S, O, bi_flag=True, fine_grained=False, batch_size=25, eval_dev_every=50, alpha=0.001)\n",
    "\n",
    "\n",
    "# Train it\n",
    "train_do(net_LSTM_1B_binary, no_improve_limit=56, plot_window=3000)\n",
    "\n",
    "\n",
    "# See how you did\n",
    "full_eval(net_LSTM_1B_binary, baseline_mean=87.5, baseline_std=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-layer vanilla LSTM (Fine-grained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.4299221039\n"
     ]
    }
   ],
   "source": [
    "# Build a 1-layer vanilla LSTM\n",
    "inp_dim = 300\n",
    "inp_dropout = 0.5\n",
    "layer_specs = [(168, 0.5)]\n",
    "\n",
    "# Build the LSTM \"stack\"\n",
    "S = network_components.LSTM_stack(inp_dim, layer_specs, inp_dropout, init_fun=network_components.ortho_weight)\n",
    "S.initialize_stack_weights(b_f_offset=1.0)\n",
    "# Add the output sigmoid layer\n",
    "O = network_components.soft_reader(S.out_dim, 5)\n",
    "\n",
    "# Create the network\n",
    "net_LSTM_1_fg = network(S, O, bi_flag=False, fine_grained=True, batch_size=25, eval_dev_every=50, alpha=0.005)\n",
    "\n",
    "\n",
    "# Train it\n",
    "train_do(net_LSTM_1_fg, no_improve_limit=56, plot_window=3000)\n",
    "\n",
    "\n",
    "# See how you did\n",
    "full_eval(net_LSTM_1_fg, baseline_mean=46.4, baseline_std=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-layer Bi-directional LSTM (Fine-grained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.8414521217\n"
     ]
    }
   ],
   "source": [
    "# Build a 1-layer vanilla LSTM\n",
    "inp_dim = 300\n",
    "inp_dropout = 0.5\n",
    "layer_specs = [(168, 0.5)]\n",
    "\n",
    "# Build the LSTM \"stack\"\n",
    "S = network_components.BiLSTM_stack(inp_dim, layer_specs, inp_dropout, init_fun=network_components.ortho_weight)\n",
    "S.initialize_stack_weights(b_f_offset=1.0)\n",
    "# Add the output sigmoid layer\n",
    "O = network_components.soft_reader(S.out_dim, 5)\n",
    "\n",
    "# Create the network\n",
    "net_LSTM_1B_fg = network(S, O, bi_flag=True, fine_grained=True, batch_size=25, eval_dev_every=50, alpha=0.001)\n",
    "\n",
    "\n",
    "# Train it\n",
    "train_do(net_LSTM_1B_fg, no_improve_limit=56, plot_window=3000)\n",
    "\n",
    "\n",
    "# See how you did\n",
    "full_eval(net_LSTM_1B_fg, baseline_mean=49.1, baseline_std=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
